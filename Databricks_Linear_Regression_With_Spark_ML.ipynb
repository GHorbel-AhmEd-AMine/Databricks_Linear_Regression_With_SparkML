{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Databricks Linear Regression With Spark ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "\n",
        "**Comment traiter des données, ajuster un modèle de régression linéaire Spark ML, évaluer les performances du modèle, stocker le modèle et faire des prédictions pour de nouvelles données ?**\n",
        "\n",
        "\n",
        "**Apache Spark dispose d’une bibliothèque pour différents types de modèles de Machine Learning.**"
      ],
      "metadata": {
        "id": "IHgzdkYKgsdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importer les bibliothèques nécessaires"
      ],
      "metadata": {
        "id": "S1wyUjzghBoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hu_4P-hhpGL",
        "outputId": "af5ea90b-8cbb-4beb-f640-4f6f4df40700"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 30 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 33.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=c27fbd85d4ba5214c16caa6f60e9dce7172213bfbadc0f3c84b8b38c62812a73\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kJ4ulSqAglDO"
      },
      "outputs": [],
      "source": [
        "# Data processing\n",
        "import pandas as pd\n",
        "\n",
        "# Create synthetic dataset\n",
        "from sklearn.datasets import make_regression  # Notre problème est un cas de régression linéraire\n",
        "# Modeling\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml import Pipeline, PipelineModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install findspark\n",
        "!pip install findspark "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fCWmoz7iz4b",
        "outputId": "d657c48d-cb81-4c44-e3de-b7ee5055925e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "#import pyspark\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#Create SparkSession\n",
        "spark = SparkSession.builder.master(\"local[1]\").appName(\"SparkByExamples.com\").getOrCreate()"
      ],
      "metadata": {
        "id": "XqNkOmmNi3cK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Créer un jeu de données pour la régression linéaire"
      ],
      "metadata": {
        "id": "sGMxyQkShm2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a synthetic dataset\n",
        "X, y = make_regression(n_samples=1000000, n_features=2, noise=0.3, bias=2, random_state=42)\n",
        "\n",
        "# Convert the data from numpy array to a pandas dataframe\n",
        "pdf = pd.DataFrame({'feature1': X[:, 0], 'feature2': X[:, 1], 'dependent_variable': y})\n",
        "\n",
        "# Convert pandas dataframe to spark dataframe\n",
        "sdf = spark.createDataFrame(pdf)\n",
        "\n",
        "# Check data summary statistics\n",
        "display(sdf.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "aD7z2qTShl-q",
        "outputId": "a53e69a0-52d8-4fc3-cebb-30f4299ede99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, feature1: string, feature2: string, dependent_variable: string]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M1dnIIX_ifUe",
        "outputId": "4d5f02dd-59f3-4f55-ca27-d53a89a9b1a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature1  feature2  dependent_variable\n",
              "0  0.313498 -0.441196           12.470413\n",
              "1  0.781497  2.459872          152.772101\n",
              "2  0.760127 -0.551061           45.344113\n",
              "3 -0.212218  0.527536            2.333974\n",
              "4 -0.034571  0.239026            7.626500"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77f46ef6-b6b1-4001-872b-b12bf353356e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>dependent_variable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.313498</td>\n",
              "      <td>-0.441196</td>\n",
              "      <td>12.470413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.781497</td>\n",
              "      <td>2.459872</td>\n",
              "      <td>152.772101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.760127</td>\n",
              "      <td>-0.551061</td>\n",
              "      <td>45.344113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.212218</td>\n",
              "      <td>0.527536</td>\n",
              "      <td>2.333974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.034571</td>\n",
              "      <td>0.239026</td>\n",
              "      <td>7.626500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77f46ef6-b6b1-4001-872b-b12bf353356e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77f46ef6-b6b1-4001-872b-b12bf353356e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77f46ef6-b6b1-4001-872b-b12bf353356e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZOx6VYal28G",
        "outputId": "5b615f42-f81d-4648-e857-61b15750be60"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[feature1: double, feature2: double, dependent_variable: double]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Test Split"
      ],
      "metadata": {
        "id": "mFtvfhKYnFhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split\n",
        "trainDF, testDF = sdf.randomSplit([.8, .2], seed=42)\n",
        "# Print the number of records\n",
        "print(f'There are {trainDF.cache().count()} records in the training dataset.')\n",
        "print(f'There are {testDF.cache().count()} records in the testing dataset.')"
      ],
      "metadata": {
        "id": "JDThBGConQBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assembleur de vecteur"
      ],
      "metadata": {
        "id": "VgD8KFy9qq4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# La régression linéaire accepte une entrée vectorielle\n",
        "vecAssembler = VectorAssembler(inputCols=['feature1', 'feature2'], outputCol=\"features\")\n",
        "vecTrainDF = vecAssembler.transform(trainDF)\n",
        "\n",
        "display(vecTrainDF)"
      ],
      "metadata": {
        "id": "PgFoHGgIqqYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ajuster le modèle de régression linéaire Spark ML"
      ],
      "metadata": {
        "id": "wyxbpnX9rLF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer un modèle de régression linéaire\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"dependent_variable\")\n",
        "# Ajuster le modèle de régression linéaire\n",
        "lrModel = lr.fit(vecTrainDF)\n",
        "# Interception et les coefficients du modèle\n",
        "print(f'The intercept of the model is {lrModel.intercept:.2f} and the coefficients of the model are {lrModel.coefficients[0]:.2f} and {lrModel.coefficients[1]:.2f}')"
      ],
      "metadata": {
        "id": "unBPtNK-rKaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alternativement, nous pouvons créer un pipeline et ajuster le modèle sur le pipeline. Un pipeline comprend généralement à la fois les étapes de traitement des données et l'étape d'ajustement du modèle.**"
      ],
      "metadata": {
        "id": "ImVTBtaRsWBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation du pipeline\n",
        "stages = [vecAssembler, lr]\n",
        "pipeline = Pipeline(stages=stages)\n",
        "\n",
        "# Ajuster le modèle sur le pipeline\n",
        "pipelineModel = pipeline.fit(trainDF)"
      ],
      "metadata": {
        "id": "RbuM0mQnslUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Performance Evaluation"
      ],
      "metadata": {
        "id": "Pq7QFvAysxcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Faire des prédictions sur le jeu de données de test\n",
        "predDF = pipelineModel.transform(testDF)\n",
        "# The output\n",
        "display(predDF.select(\"features\", \"dependent_variable\", \"prediction\"))"
      ],
      "metadata": {
        "id": "DriOO-9asx25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Après avoir obtenu les valeurs prédites, nous transmettons le nom de la colonne de prédiction et le nom de la colonne de valeur réelle dans RegressionEvaluator**\n",
        "\n",
        "metricName peut être l'une des valeurs suivantes :\n",
        "\n",
        "1) rmse : l'erreur quadratique moyenne est la valeur par défaut\n",
        "\n",
        "2) mse : erreur quadratique moyenne\n",
        "\n",
        "3) r2 : R carré\n",
        "\n",
        "4) mae : erreur absolue moyenne"
      ],
      "metadata": {
        "id": "cCKiYhrptOp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer un évaluateur de régression\n",
        "regressionEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"dependent_variable\", metricName=\"rmse\")\n",
        "\n",
        "# RMSE\n",
        "rmse = regressionEvaluator.evaluate(predDF)\n",
        "print(f\"The RMSE for the linear regression model is {rmse:0.2f}\")\n",
        "\n",
        "# MSE\n",
        "mse = regressionEvaluator.setMetricName(\"mse\").evaluate(predDF)\n",
        "print(f\"The MSE for the linear regression model is {mse:0.2f}\")\n",
        "\n",
        "# R2\n",
        "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
        "print(f\"The R2 for the linear regression model is {r2:0.2f}\")\n",
        "\n",
        "# MAE\n",
        "mae = regressionEvaluator.setMetricName(\"mae\").evaluate(predDF)\n",
        "print(f\"The MAE for the linear regression model is {mae:0.2f}\")"
      ],
      "metadata": {
        "id": "2YK50Lp_tYxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stocker le modèle"
      ],
      "metadata": {
        "id": "XgF-I8rgvT_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stocker le modèle de pipeline dans le AWS S3 bucket**"
      ],
      "metadata": {
        "id": "dnqjJMPyvjkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chemin pour stocker le modèle\n",
        "pipelinePath = '/.../model/linear_regression_pipeline_model'\n",
        "# Save the model to the path\n",
        "pipelineModel.write().overwrite().save(pipelinePath)"
      ],
      "metadata": {
        "id": "cWnf-DJgvVBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirmer que le modèle est stocké\n",
        "%fs ls '/.../model/linear_regression_pipeline_model'"
      ],
      "metadata": {
        "id": "324tUSrOvzUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Faire des prédictions pour de nouvelles données"
      ],
      "metadata": {
        "id": "zqGElri4v6V4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new synthetic dataset\n",
        "X_new, y_new = make_regression(n_samples=1000, n_features=2, bias=2, noise=0.3, random_state=0)\n",
        "\n",
        "# Convert the data from numpy array to a pandas dataframe\n",
        "pdf_new = pd.DataFrame({'feature1': X_new[:, 0], 'feature2': X_new[:, 1], 'dependent_variable': y_new})\n",
        "\n",
        "# Convert pandas dataframe to spark dataframe\n",
        "sdf_new = spark.createDataFrame(pdf_new)\n",
        "\n",
        "# Check data summary statistics\n",
        "display(sdf_new.summary())"
      ],
      "metadata": {
        "id": "D1SNVg_hv3Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "loadedPipelineModel = PipelineModel.load(pipelinePath)\n",
        "\n",
        "# Make prediction for the new dataset\n",
        "predDF_new = loadedPipelineModel.transform(sdf_new)\n",
        "\n",
        "# Take a look at the data\n",
        "display(predDF_new.select(\"features\", \"dependent_variable\", \"prediction\"))"
      ],
      "metadata": {
        "id": "kKCJUZawwCVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rassemblez tout le code"
      ],
      "metadata": {
        "id": "djMtrGqhwIwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### Step 1: Import Libraries\n",
        "# Data processing\n",
        "import pandas as pd\n",
        "# Create synthetic dataset\n",
        "from sklearn.datasets import make_regression\n",
        "# Modeling\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "###### Step 2: Create Dataset For Linear Regression\n",
        "# Create a synthetic dataset\n",
        "X, y = make_regression(n_samples=1000000, n_features=2, noise=0.3, bias=2, random_state=42)\n",
        "# Convert the data from numpy array to a pandas dataframe\n",
        "pdf = pd.DataFrame({'feature1': X[:, 0], 'feature2': X[:, 1], 'dependent_variable': y})\n",
        "# Convert pandas dataframe to spark dataframe\n",
        "sdf = spark.createDataFrame(pdf)\n",
        "# Check data summary statistics\n",
        "display(sdf.summary())\n",
        "###### Step 3: Train Test Split\n",
        "# Train test split\n",
        "trainDF, testDF = sdf.randomSplit([.8, .2], seed=42)\n",
        "# Print the number of records\n",
        "print(f'There are {trainDF.cache().count()} records in the training dataset.')\n",
        "print(f'There are {testDF.cache().count()} records in the testing dataset.')\n",
        "###### Step 4: Vector Assembler\n",
        "# Linear regression expect a vector input\n",
        "vecAssembler = VectorAssembler(inputCols=['feature1', 'feature2'], outputCol=\"features\")\n",
        "vecTrainDF = vecAssembler.transform(trainDF)\n",
        "# Take a look at the data\n",
        "display(vecTrainDF)\n",
        "###### Step 5: Fit Spark ML Linear Regression Model\n",
        "# Create linear regression\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"dependent_variable\")\n",
        "# Fit the linear regresssion model\n",
        "lrModel = lr.fit(vecTrainDF)\n",
        "# Print model intercept and coefficients\n",
        "print(f'The intercept of the model is {lrModel.intercept:.2f} and the coefficients of the model are {lrModel.coefficients[0]:.2f} and {lrModel.coefficients[1]:.2f}')\n",
        "# Create pipeline\n",
        "stages = [vecAssembler, lr]\n",
        "pipeline = Pipeline(stages=stages)\n",
        "# Fit the pipeline model\n",
        "pipelineModel = pipeline.fit(trainDF)\n",
        "###### Step 6: Model Performance Evaluation\n",
        "# Make predictions on testing dataset\n",
        "predDF = pipelineModel.transform(testDF)\n",
        "# Take a look at the output\n",
        "display(predDF.select(\"features\", \"dependent_variable\", \"prediction\"))\n",
        "# Create regression evaluator\n",
        "regressionEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"dependent_variable\", metricName=\"rmse\")\n",
        "# RMSE\n",
        "rmse = regressionEvaluator.evaluate(predDF)\n",
        "print(f\"The RMSE for the linear regression model is {rmse:0.2f}\")\n",
        "# MSE\n",
        "mse = regressionEvaluator.setMetricName(\"mse\").evaluate(predDF)\n",
        "print(f\"The MSE for the linear regression model is {mse:0.2f}\")\n",
        "# R2\n",
        "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
        "print(f\"The R2 for the linear regression model is {r2:0.2f}\")\n",
        "# MAE\n",
        "mae = regressionEvaluator.setMetricName(\"mae\").evaluate(predDF)\n",
        "print(f\"The MAE for the linear regression model is {mae:0.2f}\")\n",
        "# Visualize the data\n",
        "display(predDF.select(\"dependent_variable\", \"prediction\"))\n",
        "###### Step 7: Save Model\n",
        "# Path to save the model\n",
        "pipelinePath = '/.../model/linear_regression_pipeline_model'\n",
        "# Save the model to the path\n",
        "pipelineModel.write().overwrite().save(pipelinePath)\n",
        "# Confirm the model is saved\n",
        "%fs ls '/.../model/linear_regression_pipeline_model'\n",
        "###### Step 8: Make Predictions For New Data\n",
        "# Create a new synthetic dataset\n",
        "X_new, y_new = make_regression(n_samples=1000, n_features=2, bias=2, noise=0.3, random_state=0)\n",
        "# Convert the data from numpy array to a pandas dataframe\n",
        "pdf_new = pd.DataFrame({'feature1': X_new[:, 0], 'feature2': X_new[:, 1], 'dependent_variable': y_new})\n",
        "# Convert pandas dataframe to spark dataframe\n",
        "sdf_new = spark.createDataFrame(pdf_new)\n",
        "# Check data summary statistics\n",
        "display(sdf_new.summary())\n",
        "# Load the saved model\n",
        "loadedPipelineModel = PipelineModel.load(pipelinePath)\n",
        "# Make prediction for the new dataset\n",
        "predDF_new = loadedPipelineModel.transform(sdf_new)\n",
        "# Take a look at the data\n",
        "display(predDF_new.select(\"features\", \"dependent_variable\", \"prediction\"))\n",
        "# Actual vs. predicted\n",
        "display(predDF_new.select(\"dependent_variable\", \"prediction\"))"
      ],
      "metadata": {
        "id": "cdUwW3CBwKNz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}